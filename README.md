# Cyber_Security_news_scrapping

## Extraction, Analyse et ModÃ©lisation de DonnÃ©es Textuelles en CybersÃ©curitÃ©

---

## ğŸ“Š Vue d'Ensemble ExÃ©cutive

Ce projet dÃ©montre une **pipeline complÃ¨te d'analyse textuelle** spÃ©cialisÃ©e en cybersÃ©curitÃ©, englobant 4 phases:

1. **Collecte** (30 articles)
2. **PrÃ©traitement** (15,976 tokens)
3. **Analyse TF-IDF** (1,000 termes, 5 clusters)
4. **ModÃ©lisation SÃ©mantique** (2,159 embeddings Word2Vec)

**RÃ©sultat Final:** Rapport PDF complet + visualisations + donnÃ©es analysÃ©es

---

## ğŸ“ Structure du Projet

```
projet_ead/
â”œâ”€â”€ 1.Collecte_de_Donnees/
â”‚   â”œâ”€â”€ scrapers/
â”‚   â”‚   â”œâ”€â”€ base.py          # Classe abstraite BaseScraper
â”‚   â”‚   â”œâ”€â”€ bleepingcomputer.py  # 20 articles âœ“
â”‚   â”‚   â””â”€â”€ krebs.py         # 10 articles âœ“
â”‚   â””â”€â”€ main.py              # DataCollector orchestration
â”‚
â”œâ”€â”€ 2.Pretraitement_et_Nettoyage_du_Texte/
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ normalizer.py
â”‚   â”‚   â”œâ”€â”€ tokenizer.py
â”‚   â”‚   â”œâ”€â”€ stopwords_filter.py
â”‚   â”‚   â”œâ”€â”€ lemmatizer.py
â”‚   â”‚   â””â”€â”€ preprocessor.py
â”‚   â””â”€â”€ run.py
â”‚
â”œâ”€â”€ 3.Analyse_de_Frequence_et_PondÃ©ration/
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ tfidf_analyzer.py
â”‚   â”‚   â”œâ”€â”€ keyword_extractor.py
â”‚   â”‚   â””â”€â”€ thematic_analyzer.py
â”‚   â””â”€â”€ run.py
â”‚
â”œâ”€â”€ 4.Modelisation_Semantique/
â”‚   â”œâ”€â”€ modules/
â”‚   â”‚   â”œâ”€â”€ semantic_trainer.py
â”‚   â”‚   â”œâ”€â”€ semantic_explorer.py
â”‚   â”‚   â””â”€â”€ semantic_visualizer.py
â”‚   â””â”€â”€ run.py
â”‚
â””â”€â”€ data/
    â”œâ”€â”€ articles_cybersecurity.json      # 30 articles bruts
    â”œâ”€â”€ articles_preprocessed.json       # Tokens traitÃ©s
    â”œâ”€â”€ tfidf_analysis.json             # Analyse TF-IDF
    â”œâ”€â”€ semantic_analysis.json          # RÃ©sultats Word2Vec
    â”œâ”€â”€ word2vec_model                  # ModÃ¨le entraÃ®nÃ©
    â””â”€â”€ visualizations/
        â”œâ”€â”€ word2vec_space.png          # t-SNE embedding
        â””â”€â”€ word2vec_clusters.png       # Clusters thÃ©matiques
```

---

## ğŸ” RÃ©sultats DÃ©taillÃ©s par Phase

### Phase 1: Collecte de DonnÃ©es

**Statistiques:**
- Articles collectÃ©s: **30**
- BleepingComputer: **20** articles âœ“
- Krebs on Security: **10** articles âœ“
- TheHackerNews: 0 articles (JavaScript requis)
- SecurityWeek: 0 articles (JavaScript requis)

**Technologies:** requests, BeautifulSoup4, lxml

**Justification:** BeautifulSoup4 lÃ©ger vs Selenium (30x plus lent) pour 70% sources

---

### Phase 2: PrÃ©traitement Textuel

**Statistiques:**
- Articles traitÃ©s: **30**
- Total tokens: **15,976**
- Moyenne tokens/article: **533**
- Min/Max: **189 / 2,430**

**Pipeline Normalisation:**
1. Minuscules
2. Suppression URLs/emails (regex)
3. Suppression nombres et ponctuation
4. Tokenisation (split)
5. Filtrage stop words (NLTK)
6. Lemmatisation (WordNetLemmatizer)

**Architecture Modulaire:**
```
normalizer.py (36 lignes) â†’ Normalisation
    â†“
tokenizer.py (7 lignes) â†’ Tokenisation
    â†“
stopwords_filter.py (28 lignes) â†’ Filtrage
    â†“
lemmatizer.py (42 lignes) â†’ Lemmatisation
    â†“
preprocessor.py (47 lignes) â†’ Orchestration
```

**Technologies:** NLTK, unidecode

---

### Phase 3: Analyse TF-IDF

**Statistiques:**
- Matrice dimensions: **30 Ã— 1,000**
- DensitÃ©: **18.4%** (normal pour NLP)
- Termes uniques: **1,000**
- Clusters K-means: **5**

**Distribution clusters:**
- Cluster 0: 4 documents
- Cluster 1: 8 documents
- Cluster 2: 4 documents
- Cluster 3: 7 documents
- Cluster 4: 7 documents

**Top 10 Keywords:**
```
1. data      (0.0662)
2. iam       (0.0624)
3. window    (0.0556)
4. said      (0.0528)
5. university (0.0522)
6. domain    (0.0473)
7. microsoft (0.0463)
8. ransomware (0.0448)
9. service   (0.0427)
10. cve      (0.0425)
```

**Technologies:** scikit-learn TfidfVectorizer

**ParamÃ¨tres:**
- max_features: 1000
- min_df: 2 (ignorer < 2 documents)
- max_df: 0.8 (exclure > 80%)

---

### Phase 4: ModÃ©lisation SÃ©mantique

**Statistiques Word2Vec:**
- Phrases d'entraÃ®nement: **30 articles**
- Corpus total: **15,976 mots**
- Vocabulaire initial: **4,513 mots**
- Vocabulaire final: **2,159 mots**
- Taux conservation: **47.84%**
- Dimensions vecteurs: **200**
- DurÃ©e entraÃ®nement: **0.4 secondes**
- Vitesse: **308,501 mots/sec**

**SimilaritÃ©s TrouvÃ©es:**
```
ransomware  â†’ clop, harvard, oracle
cloud       â†’ european, test, distributed
attack      â†’ ransomware, oracle, clop
data        â†’ individual, breach, million
microsoft   â†’ update, bug, code
vulnerability â†’ cve, firewall, flaw
```

**Analogies SÃ©mantiques (50% succÃ¨s):**
```
âœ“ internet - network â‰ˆ system - ? â†’ recent
âœ“ sql - database â‰ˆ file - ? â†’ github
âœ— cloud - aws â‰ˆ microsoft - ? â†’ aws absent
âœ— ransomware - encrypt â‰ˆ malware - ? â†’ encrypt absent
```

**Structure SÃ©mantique (4 clusters thÃ©matiques):**
1. **Cluster SÃ©curitÃ©:** ransomware, attack, vulnerability, cve, firewall, flaw
2. **Cluster Infrastructure:** cloud, distributed, test, update, service
3. **Cluster Data:** data, breach, individual, million, storage
4. **Cluster Network:** network, internet, connection, bandwidth, protocol

**Technologies:** Gensim Word2Vec Skip-gram, scikit-learn t-SNE

**ParamÃ¨tres Word2Vec:**
- Algorithme: Skip-gram (sg=1)
- Vector size: 200
- Window: 5
- Min count: 2
- Epochs: 10
- Workers: 4

---

## ğŸ¯ Choix d'ImplÃ©mentation JustifiÃ©s

### 1. Architecture Modulaire

**Principe:** Chaque phase = module indÃ©pendant

**Avantages:**
- ExÃ©cution indÃ©pendante des phases
- ReutilisabilitÃ© des composants
- TestabilitÃ© isolÃ©e
- Maintenance facilitÃ©e
- Ã‰volutivitÃ© (ajouter phases)

**Exemple:** Peut re-entraÃ®ner Word2Vec sans re-scraper articles

---

### 2. BeautifulSoup4 vs Alternatives

| Aspect | BeautifulSoup4 | Selenium | Scrapy |
|--------|---|---|---|
| Poids | LÃ©ger | Lourd | Lourd |
| Vitesse | Rapide | 30x plus lent | Rapide |
| JavaScript | Non | Oui | Non |
| Apprentissage | Facile | Complexe | Complexe |
| **Choix** | **âœ“ SÃ©lectionnÃ©** | | |

**Raison:** Optimal pour 70% sources statiques, Ã©vite overhead inutile

---

### 3. NLTK vs Spacy Lemmatisation

| Aspect | NLTK | Spacy |
|--------|------|-------|
| PrÃ©cision | TrÃ¨s bonne | Bonne |
| RapiditÃ© | Moyen | TrÃ¨s rapide |
| Petits corpus | IdÃ©al | Overkill |
| DÃ©pendances | Minimales | Lourdes |
| **Choix** | **âœ“ SÃ©lectionnÃ©** | |

**Raison:** Plus prÃ©cis pour corpus spÃ©cialisÃ© petit, dÃ©pendances minimales

---

### 4. scikit-learn vs Gensim TF-IDF

**Choix:** scikit-learn TfidfVectorizer

**Justification:**
- ImplÃ©mentation optimisÃ©e
- Matrices sparse efficaces (18.4% densitÃ©)
- K-means intÃ©grÃ©
- Production-ready
- Bien documentÃ©

---

### 5. Word2Vec Skip-gram vs CBOW vs FastText

| CritÃ¨re | Skip-gram | CBOW | FastText |
|---------|-----------|------|----------|
| Mots rares | Excellent | Moyen | TrÃ¨s bon |
| RapiditÃ© | Moyen | Rapide | Rapide |
| Petits corpus | IdÃ©al | Moins bon | Bon |
| Morphologie | Non | Non | Oui |
| **Choix** | **âœ“ SÃ©lectionnÃ©** | | |

**Raison:** Skip-gram excellent pour termes rares domaine-spÃ©cifique

---

### 6. t-SNE vs PCA vs UMAP

| CritÃ¨re | t-SNE | PCA | UMAP |
|---------|-------|-----|------|
| Clusters locaux | Excellent | Mauvais | Bon |
| GÃ©omÃ©trie globale | Non | Oui | Oui |
| Vitesse | Moyen | Rapide | Rapide |
| ParamÃ©trisation | Facile | Triviale | Complexe |
| **Choix** | **âœ“ SÃ©lectionnÃ©** | | |

**Raison:** Visualisation clusters locaux optimale pour interprÃ©tation

---

## âš ï¸ Limitations IdentifiÃ©es

### 1. Taille Corpus (30 articles)
**Impact:** Petit pour statistiques robustes, analogies limitÃ©es

**Solutions:**
- Augmenter Ã  100+ articles
- RÃ©duire min_count Ã  1
- Augmenter vector_size Ã  300-500

### 2. Sources JavaScript (3 sources)
**Impact:** 10% corpus potentiel non collectÃ©

**Solutions:**
- ImplÃ©menter Selenium
- Ajouter Playwright
- Utiliser puppeteer

### 3. Termes Rares
**Impact:** aws, encrypt trop peu contexte

**Solutions:**
- Augmenter corpusf
- RÃ©duire seuils filtrage
- FastText pour morphologie

### 4. Taux SuccÃ¨s Analogies (50%)
**Impact:** Petit corpus limite relations sÃ©mantiques

**Solutions:**
- Augmenter articles
- Tester CBOW
- Fine-tuning domaine-spÃ©cifique


---

## ğŸ“Š Statistiques Finales

| MÃ©trique | Valeur |
|----------|--------|
| **DurÃ©e totale projet** | 1 jour |
| **Lignes code Python** | ~500 |
| **Fichiers Python** | 20+ |
| **Articles analysÃ©s** | 30 |
| **Tokens traitÃ©s** | 15,976 |
| **Termes uniques** | 1,000 |
| **Embeddings appris** | 2,159 |
| **Clusters identifiÃ©s** | 5 |
| **Visualisations** | 2 PNG |
| **Taille donnÃ©es** | ~5 MB |
| **Temps entraÃ®nement total** | < 10 sec |

---



---

## âœ… RÃ©alisations

âœ“ Pipeline complÃ¨te fonctionnelle
âœ“ Architecture modulaire et maintenable
âœ“ DonnÃ©es de qualitÃ© collectÃ©es
âœ“ Analyse statistique rigoureuse
âœ“ ModÃ©lisation sÃ©mantique validÃ©e
âœ“ Visualisations gÃ©nÃ©rÃ©es
âœ“ Documentation exhaustive
âœ“ Rapport PDF professionnel

---

## ğŸ“ Conclusion

Ce projet dÃ©montre une **approche systÃ©matique et rigoureuse** de l'analyse textuelle spÃ©cialisÃ©e. Les rÃ©sultats montrent une structure sÃ©mantique cohÃ©rente dans le corpus cybersÃ©curitÃ©, avec 4 clusters thÃ©matiques bien distincts.

**Points forts:** Architecture modulaire, technologies appropriÃ©es, documentation complÃ¨te

**Axes d'amÃ©lioration:** Augmentation corpus, gestion JavaScript, modÃ¨les avancÃ©s

